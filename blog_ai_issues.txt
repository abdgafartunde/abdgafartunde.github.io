The Great Deskilling: How We Solved Cognitive Scarcity and Accidentally Made Deep Thinking Rare

I’ve been thinking about this for months, and the more I watch PhD students, postdocs, and even senior colleagues interact with the new generation of AI tools, the clearer it becomes: we are living through one of the purest examples in history of a solution that births a brand-new, subtler problem.

We spent centuries complaining that good thinking and good writing were too slow, too hard, too exclusive. Not enough people had the time, the training, or the raw horsepower to produce rigorous proofs, beautiful expositions, or genuinely novel analyses. Then, almost overnight, the large models arrived and removed every bottleneck at once.

Need a literature review? Here are 60 papers summarised in perfect academic English.  
Stuck on a proof? Ask for a hint, an outline, or the whole thing in clean LaTeX.  
Want a grant proposal that reads like it was written by a native English-speaking professor with 20 years of experience? Ten seconds.

Problem solved. Cognitive scarcity is dead.

Except… something strange is happening.

I now see brilliant applied math PhD students who can generate a flawless 25-page survey on fractional PDEs in an afternoon, yet freeze when you take the model away and ask them to summarise three papers by hand. I see postdocs who have published four first-author papers in the last year but struggle to explain, without looking at their own LaTeX, why the adjoint, why the homotopy method actually converges faster than fixed-point iteration in their specific case. I see referees complaining that the new submissions from young researchers are “too smooth” — suspiciously well-written, suspiciously average in insight.

We didn’t just augment human intelligence. We replaced large parts of the slow, painful process that used to forge critical thinkers.

Let me be clear: I use these tools every day. I love them. They let me explore ideas ten times faster than five years ago. But love is not the same as blindness.

What we have done is the intellectual equivalent of inventing the car and then noticing, twenty years later, that hardly anyone under 30 knows how to walk long distances anymore. The muscle simply atrophied because it was no longer needed for daily survival.

The old muscle was built through years of:
- staring at a blank page until it hurt  
- re-reading the same paragraph ten times to find the flaw  
- copying proofs by hand to internalise them  
- writing terrible first drafts and slowly chiselling them into something defensible  
- failing, again and again, in seminars and reading groups

Those experiences were miserable, but they were also the gym where independent thinking was built.

Remove the pain and you often remove the gain.

This is not an anti-AI rant. It is an observation of a phase transition. We have moved from a world where depth was limited by access to a world where depth is limited by deliberate resistance. The new scarce resource is not computational power or information — it is the ability and the will to think without a safety net.

The best young mathematicians I know now have a new, almost ascetic discipline: they force themselves to solve problems on paper first, to write the first draft without autocomplete, to read papers without asking Claude for a summary. They treat the models the way rock climbers treat bolts — useful protection, but you don’t clip in until you absolutely have to. The goal is still to free-solo the hard parts when possible, because that is what keeps the skill alive.

And paradoxically, these are exactly the people who end up using AI the most effectively — because they understand what the machine is actually doing, where it is likely to hallucinate, and how to steer it toward genuine novelty instead of polished mediocrity.

So yes, we solved the ancient problem of cognitive scarcity.  
And in doing so we created a new, quieter scarcity: the scarcity of humans who can still think deeply when the model is turned off.

If that doesn’t scare you a little, it should.

Because in mathematics, more than almost anywhere else, the thing that separates the good from the great has never been speed of writing or breadth of literature coverage. It has always been the ability to sit alone with a problem long enough for something truly new to emerge.

I’m not sure we have figured out yet how to keep that alive in a world where the easiest path is to never be alone with a problem again.

What do you think — are we training the last generation of deep thinkers who still know how to struggle, or are we simply forcing the struggle to move somewhere new, somewhere harder to see?

Either way, the game has changed forever.

And the new prize goes not to the smartest, not to the fastest, but to those disciplined enough to keep parts of their mind permanently offline.
