---
layout: post
title: "We Fixed Cognitive Scarcity. Now What?"
description: "Some scattered thoughts on AI tools, the disappearing art of struggling with ideas, and why I'm a little worried."
date: 2026-02-06
tags: [AI, Academia, Reflections]
---

This has been bothering me for a while now.

I keep watching people around me—PhD students, postdocs, professors—use LLMs. And I keep noticing something that doesn't sit right.

For centuries we complained that thinking deeply was too slow. Writing well was too hard. Not enough people had the training or the bandwidth to do rigorous work. Then ChatGPT showed up, and suddenly all those bottlenecks vanished.

Literature review? Done in minutes.  
Stuck on a proof? Ask for hints.  
Grant proposal in polished academic English? Just paste your notes.

Okay. Great. Problem solved, right?

Here's what I'm actually seeing:

A brilliant student in my department can produce a 25-page survey on fractional PDEs in a single afternoon. Ask him to summarize three papers *by hand* without any tools, and he freezes. Another postdoc published four papers last year but couldn't explain to me, off the top of his head, why the adjoint method actually works in his setup. He'd have to look at his own LaTeX.

Reviewers are starting to notice too. The manuscripts coming through are "too smooth"—clean prose, correct math, but weirdly generic. Like the edges got sanded off somewhere.

I don't think we augmented intelligence. I think we outsourced the struggle. And the struggle might have been the point.

## What We Lost

Think about how you actually learned to think:

Staring at a blank page for hours. Reading the same paragraph eight times trying to find what's wrong. Copying proofs by hand because nothing else made them stick. Writing a terrible first draft, hating it, and slowly beating it into shape over weeks.

None of that was fun. But it was the gym.

Now there's no reason to do any of it. Why stare at a blank page when you can ask for an outline? Why struggle with your exposition when the machine writes better English than you do?

The mental muscle atrophies when you stop using it. We invented the car and now we've forgotten how to walk.

## What Actually Works

The sharpest young researchers I know have figured something out. They do the hard parts first—on paper, no autocomplete, no "help me structure this." They only reach for the tools *after* they've wrestled with the problem themselves.

One friend described it like rock climbing: the bolts are there for protection, but you don't clip in unless you have to. Free-solo when you can, because that's what keeps you sharp.

These same people end up being the best at using AI, because they know where it breaks. They know what a hallucination smells like. They know how to push the model toward something real instead of something that just *sounds* real.

## I Don't Know What to Do About This

I'm not anti-AI. I use these tools constantly. They've made me faster.

But speed was never the hard part of math. The hard part was sitting with a problem long enough that something genuinely new could emerge. And now the default path is to never sit alone with a problem at all.

I don't have answers. I just know that the prize used to go to whoever could think the deepest, and now I'm not sure that's true anymore. Maybe it goes to whoever still *chooses* to think deeply, even when they don't have to.

---

Is that sustainable? Can you train deep thinkers in a world where shallow thinking gets you 80% of the way there?

I honestly don't know. But it keeps me up at night.
